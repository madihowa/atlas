from keras.callbacks import ModelCheckpoint
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
import seaborn as sb
import pandas as pd
import numpy as np
from Graphics import plt_result
import warnings
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.simplefilter(action='ignore', category=FutureWarning)
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from CSV_read_write import *
import os
import matplotlib.pyplot as plt

debug_NN_predict = False
debug_NN_input = False
# import tensorflow as tf
# from keras.models import Sequential
# from keras.layers import Dense
# from keras.wrappers.scikit_learn import KerasRegressor
# from sklearn.model_selection import cross_val_score
# from sklearn.model_selection import KFold
# from sklearn.preprocessing import StandardScaler
# from sklearn.pipeline import Pipeline

#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
#from tensorflow.python.client import device_lib


# print(device_lib.list_local_devices())
# print("Started")
# print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
def FitNetwork(dir):

    df_test, df_train = split()
#    target=df_train.z`
    target = df_train['truthE']
    df_train.drop(['truthE'],axis = 1 , inplace = True)
#    list_num_cols = get_cols_with_no_nans(df_train, 'num')


#    df_test = df_test[list_num_cols]
#    df_train = df_train[list_num_cols]
    df_test.hist(figsize = (12,10))
    if debug_NN_input:
        for col in df_train.columns:
            print(col, end = ': ')
            print(df_test.iloc[0][col])



    NN_model = Sequential()

    #Input
    NN_model.add(Dense(128, kernel_initializer='normal',input_dim = df_train.shape[1], activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))

    # The Output Layer :
    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))

    # Compile the network :
    NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
    NN_model.summary()


    checkpoint_name = dir+'/Weights-{epoch:03d}--{val_loss:.5f}.hdf5'
    checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')
    callbacks_list = [checkpoint]

    NN_model.fit(df_train, target, epochs=50, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)
    #
def NetworkPredict(dir):


    ##Prepare the data for testing
    df_test, df_train = split()
    #    target=df_train.z`
    target = df_train['truthE']
    df_train.drop(['truthE'],axis = 1 , inplace = True)
    list_num_cols = get_cols_with_no_nans(df_train, 'num')
    df_train = df_train[list_num_cols]


    #############################################################################################################################
    ##Build the Network
    #############################################################################################################################
    NN_model = Sequential()

    #Input
    NN_model.add(Dense(128, kernel_initializer='normal',input_dim = df_train.shape[1], activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))
    NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))

    # The Output Layer :
    NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))

    # Compile the network :
    NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])
    NN_model.summary()

    #############################################################################################################################
    ##Load the best weights from training
    #############################################################################################################################
    file = find_min_weights(dir)
    min_loss = None
    pwd = os.getcwd()


    wights_file = file # choose the best checkpoint
    NN_model.load_weights(wights_file) # load it
    NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])

    ##Make predictions
    predictions = NN_model.predict(df_train)



    #Plot the results
    plt_result(df_train, predictions, target)
    #Save Results as CSV file
    # plt.show()
    plt.savefig(dir + "/figures")

    if debug_NN_predict:
        print("The target is type: ", end='')
        print(type(target))
        print("The prediction is type: ", end='')
        print(type(predictions))
        for col in df_train.columns:
            print(col, end = ': ')
            print(df_test.iloc[0][col])


    # write_csv_file(df_train, dir, predictions, target)
    df_train['truthE'] = target
    df_train['Predicted_Value'] = predictions
    write_csv_file(df_train, dir)
